{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whatsapp Chat Analyzer\n",
    "\n",
    "This code generates some interesting data visualization for a whatsapp group chat history.\n",
    "\n",
    "This takes the group chat history text as an input.\n",
    "\n",
    "To export group chat history in whatsapp, go to group chat > Settings > More > Export Chat > Without Media\n",
    "\n",
    "You need the following libraries in your python environment\n",
    "nltk (Also download nltk data stopwords and vader_lexicon)\n",
    "matplotlib\n",
    "\n",
    "\n",
    "Reference: https://towardsdatascience.com/build-your-own-whatsapp-chat-analyzer-9590acca9014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining some static variables for regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(60,1)\n",
    "# #size in inches for the plot\n",
    "# plt_size = [12,480]\n",
    "\n",
    "\n",
    "mediaPattern = r\"(\\<Media omitted\\>)\" # Because it serves no purpose\n",
    "regexMedia = re.compile(mediaPattern, flags=re.M)\n",
    "\n",
    "dateAndTimepattern = r\"(\\d+\\/\\d+\\/\\d+)(,)(\\s)(\\d+:\\d+)(\\s)(\\w+)(\\s)(-)(\\s\\w+)*(:)\"\n",
    "regexDate = re.compile(dateAndTimepattern, flags=re.M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define path to the input text file & read the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(filename):\n",
    "    chat = open(filename, 'r', encoding='utf-8')\n",
    "    chatText = chat.read()\n",
    "    chat.close()\n",
    "\n",
    "    lines = []\n",
    "    for line in chatText.splitlines():\n",
    "        if line.strip() is not \"\": # If it's empty, we don't need it\n",
    "            lines.append(line.strip())\n",
    "    return lines\n",
    "\n",
    "lines = readFile(\"<path to text file>\")\n",
    "\n",
    "print('Number of lines in the file: ' + str(len(lines)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse all lines and convert into a tuple of date, time, author and message.\n",
    "\n",
    "Each line which starts with a date is the start of a new message, followed by time, author and a single / multi line message.\n",
    "\n",
    "Join multi line messages into a single string.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(lines):\n",
    "    parsed_data = []\n",
    "    message_buffer = []\n",
    "    date, time, author = None, None, None\n",
    "    for line in lines:\n",
    "\n",
    "        if starts_with_date(line): # If a line starts with a Date Time pattern, then this indicates the beginning of a new message\n",
    "            # print(line)\n",
    "            if len(message_buffer) > 0: # Check if the message buffer contains characters from previous iterations\n",
    "                parsed_data.append([date, time, author, ' '.join(message_buffer)]) # Save the tokens from the previous message in parsedData\n",
    "            message_buffer.clear() # Clear the message buffer so that it can be used for the next message\n",
    "            date, time, author, message = get_data_point(line) # Identify and extract tokens from the line\n",
    "            message_buffer.append(message) # Append message to buffer\n",
    "        else:\n",
    "                message_buffer.append(line)\n",
    "\n",
    "    return parsed_data\n",
    "\n",
    "\n",
    "def starts_with_date(s):\n",
    "    pattern = '[0-9]{1,2}/[0-9]{1,2}/[0-9]{1,2}, [0-9]{1,2}:[0-9]{1,2} [AP]M -'\n",
    "    result = re.match(pattern, s)\n",
    "    if result:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def starts_with_author(s):\n",
    "    patterns = [\n",
    "        '([\\w]+):',                        # First Name\n",
    "        '([\\w]+[\\s]+[\\w]+):',              # First Name + Last Name\n",
    "        '([\\w]+[\\s]+[\\w]+[\\s]+[\\w]+):',    # First Name + Middle Name + Last Name\n",
    "        '([+]\\d{2} \\d{5} \\d{5}):',         # Mobile Number (India)\n",
    "        '([+]\\d{2} \\d{3} \\d{3} \\d{4}):',   # Mobile Number (US)\n",
    "        '([+]\\d{2} \\d{4} \\d{7})'           # Mobile Number (Europe)\n",
    "    ]\n",
    "    pattern = '^' + '|'.join(patterns)\n",
    "    result = re.match(pattern, s)\n",
    "    if result:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_data_point(line):\n",
    "    # line = 18/06/17, 22:47 - Loki: Why do you have 2 numbers, Banner?\n",
    "\n",
    "    split_line = line.split(' - ')  # split_line = ['18/06/17, 22:47', 'Loki: Why do you have 2 numbers, Banner?']\n",
    "\n",
    "    date_time = split_line[0]  # date_time = '18/06/17, 22:47'\n",
    "\n",
    "    date, time = date_time.split(', ')  # date = '18/06/17'; time = '22:47'\n",
    "\n",
    "    message = ' '.join(split_line[1:])  # message = 'Loki: Why do you have 2 numbers, Banner?'\n",
    "\n",
    "    if starts_with_author(message):  # True\n",
    "        split_message = message.split(': ')  # split_message = ['Loki', 'Why do you have 2 numbers, Banner?']\n",
    "        author = split_message[0]  \n",
    "        message = ' '.join(split_message[1:])  # message = 'Why do you have 2 numbers, Banner?'\n",
    "    else:\n",
    "        author = None\n",
    "    return date, time, author, message\n",
    "\n",
    "data = get_data(lines)\n",
    "print('Number of messages ' + str(len(data)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse all lines and convert into a dataframe with 4 columns - 'Date', 'Time', 'Author', 'Message'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_frame(data):\n",
    "    df = pd.DataFrame(data, columns=['Date', 'Time', 'Author', 'Message'])\n",
    "    df.head()\n",
    "    df.drop(df.index[:1], inplace=True)\n",
    "    df.to_csv(index=False, path_or_buf='C:/temp/out.csv' )\n",
    "    return df\n",
    "\n",
    "df = get_data_frame(data)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print last few messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export data frame to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path_or_buf='C:/temp/df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot horizontal bar graph of Author vs Number of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_messages_by_author(df):\n",
    "    #Total messages by Author\n",
    "    author_value_counts = df['Author'].value_counts() \n",
    "    # Number of messages per author\n",
    "    #pprint(author_value_counts)\n",
    "    top_10_author_value_counts = author_value_counts.head(18)\n",
    "    # Number of messages per author for the top 10 most active authors\n",
    "    plt = top_10_author_value_counts.plot.barh( figsize=[12,8],\n",
    "                                               title='Most Messages (Highly Talkative)') # Plot a bar chart using pandas built-in plotting apis\n",
    "    \n",
    "    \n",
    "print_messages_by_author(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot horizontal bar graph of Author vs Number of media messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     \n",
    "def print_media_messages_by_author(df):\n",
    "    #Media messages by Author\n",
    "    # Plot a bar chart using pandas built-in plotting apis\n",
    "    media_messages_df = df[df['Message'] == '<Media omitted>']\n",
    "    media_messages_count = media_messages_df['Author'].value_counts() \n",
    "    #pprint(media_messages_count)\n",
    "    media_messages_count.plot.barh(figsize=[12,8], title='Most Photos') \n",
    "    \n",
    "    return media_messages_df\n",
    "\n",
    "media_messages_df = print_media_messages_by_author(df)\n",
    "print('Total number of media messages: ' + str(len(media_messages_df.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove media messages for further analysis of text messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_media_messages(df, media_messages_df):\n",
    "    #Remove media messages\n",
    "    messages_df = df.drop(media_messages_df.index) # Drops all rows of the data frame containing media messages\n",
    "    messages_df.head()\n",
    "    #print(messages_df)\n",
    "    return messages_df\n",
    "\n",
    "messages_df = remove_media_messages(df, media_messages_df)\n",
    "print('Total number of non media messages: ' + str(len(messages_df.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add new columns word count and letter counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_word_count(messages_df):\n",
    "    messages_df['Letter_Count'] = messages_df['Message'].apply(lambda s : len(s))\n",
    "    messages_df['Word_Count'] = messages_df['Message'].apply(lambda s : len(s.split(' ')))\n",
    "    print('Total Number of words: ' + str(messages_df['Word_Count'].sum()))\n",
    "    print('Total Number of letters: ' + str(messages_df['Letter_Count'].sum()))\n",
    "    return messages_df\n",
    "\n",
    "\n",
    "messages_df = add_word_count(messages_df)\n",
    "messages_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot horizontal bar graph of Author vs word count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_word_count_by_author(messages_df):\n",
    "    #Word count by Author \n",
    "    total_word_count_grouped_by_author = messages_df[['Author',\n",
    "                                                      'Word_Count']].groupby('Author').sum()\n",
    "    sorted_total_word_count_grouped_by_author = total_word_count_grouped_by_author.sort_values('Word_Count',\n",
    "                                                                                               ascending=False)\n",
    "    top_10_sorted_total_word_count_grouped_by_author = sorted_total_word_count_grouped_by_author.head(20)\n",
    "    top_10_sorted_total_word_count_grouped_by_author.plot.barh(figsize=[12,8], \n",
    "                                                            title='Most words (Truly Talkative)')\n",
    "\n",
    "    \n",
    "print_word_count_by_author(messages_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot horizontal bar graph of Author vs Letter count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_letter_count_by_author(messages_df):\n",
    "    total_letter_count_grouped_by_author = messages_df[['Author', 'Letter_Count']].groupby('Author').sum()\n",
    "    sorted_total_letter_count_grouped_by_author = total_letter_count_grouped_by_author.sort_values('Letter_Count', ascending=False)\n",
    "    top_10_sorted_total_letter_count_grouped_by_author = sorted_total_letter_count_grouped_by_author.head(16)\n",
    "    top_10_sorted_total_letter_count_grouped_by_author.plot.barh( figsize=[12,8],title='Most letters (Typist)')\n",
    "\n",
    "print_letter_count_by_author(messages_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot most active dates for the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_most_active_dates(messages_df):\n",
    "    #Date with most messages\n",
    "    date_counts = messages_df['Date'].value_counts()\n",
    "    #print(date_counts)\n",
    "    date_counts.sort_values(ascending=False).head(10).plot.barh(figsize=[12,8],title='Most active days ') \n",
    "   \n",
    "               \n",
    "print_most_active_dates(messages_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot most active dates for each person in the group \n",
    "\n",
    "In terms of sending messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "number_of_authors = len(set(messages_df['Author']))\n",
    "fig, axs = plt.subplots(number_of_authors-1,1)\n",
    "plot_size=[12, number_of_authors*8]\n",
    "\n",
    "def print_most_active_dates_by_author(messages_df):\n",
    "    i = 0\n",
    "    for author in set(messages_df['Author']):\n",
    "        messages_author = messages_df.loc[messages_df['Author'] == author]\n",
    "        \n",
    "        if len(messages_author > 0):\n",
    "            date_counts = messages_author['Date'].value_counts()\n",
    "            date_counts.sort_values(ascending=False).head(10).plot.barh(ax=axs[i],\n",
    "                                    figsize=plot_size,title='Most active days ' + author) \n",
    "            i+=1\n",
    "   \n",
    "\n",
    "print_most_active_dates_by_author(messages_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot horizontal bar graph for number of messages vs hour of the day\n",
    "\n",
    "Create a new column hour from date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_most_active_hour(messages_df):\n",
    "    #Time with most messages\n",
    "    messages_df['Hour'] = messages_df['Time'].apply(lambda x : int(x.split(':')[0]) if 'AM' in x else int(x.split(':')[0]) + 12 )\n",
    "    messages_df['Hour'].value_counts().sort_index(ascending=False).plot.barh(\n",
    "         figsize=[12,8], title='Most active time')\n",
    "    \n",
    "print_most_active_hour(messages_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot number of messages vs hour for each person in the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_authors = len(set(messages_df['Author']))\n",
    "fig, axs = plt.subplots(number_of_authors - 1,1)\n",
    "plot_size=[12, number_of_authors*8]\n",
    "\n",
    "def print_most_active_hour_by_author(messages_df):\n",
    "    i = 0\n",
    "    for author in set(messages_df['Author']):\n",
    "        messages_author = messages_df.loc[messages_df['Author'] == author]\n",
    "        if len(messages_author > 0):\n",
    "         #Time with most messages\n",
    "            messages_author['Hour'].value_counts().sort_index(ascending=False).plot.barh(\n",
    "                ax=axs[i],  figsize=plot_size, title='Most active time ' + author)\n",
    "            i+=1\n",
    "            \n",
    "        \n",
    "print_most_active_hour_by_author(messages_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize all messages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "messages_df['Tokens'] = messages_df['Message'].apply(tokenizer.tokenize)\n",
    "messages_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all unique words.\n",
    "\n",
    "Remove all stop words.\n",
    "\n",
    "Plot frequency distribution of all words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = {word for tokens in messages_df.Tokens for word in tokens}\n",
    "all_words = [word for tokens in messages_df.Tokens for word in tokens]\n",
    "print(\"Total number of unique words \"+ str(len(unique_words)))\n",
    "# pprint(all_words)\n",
    "\n",
    "sr = stopwords.words('english')\n",
    "clean_tokens = [t for t in all_words if t not in stopwords.words('english')]\n",
    "word_frequency_dist = nltk.FreqDist(clean_tokens)\n",
    "word_frequency_dist.plot(20, cumulative=False, title='Most used words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find most repeating trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_frequency_dist = nltk.FreqDist(nltk.everygrams(clean_tokens, min_len=3, max_len=3))\n",
    "    \n",
    "\n",
    "print('Top 50 3 letter sequences: ')\n",
    "print(trigram_frequency_dist.most_common(50))\n",
    "trigram_frequency_dist.plot(20,cumulative=False, title='Most used bigrams')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get sentiment of each message\n",
    "\n",
    "Create a new column Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "messages_df['Sentiment'] = messages_df['Message'].apply(sentiment_analyzer.polarity_scores)\n",
    "messages_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot a pie chart for overall sentiment of the group chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sentiments(sentiment_scores):\n",
    "    \n",
    "    positives = np.array([x['pos'] for x in sentiment_scores])\n",
    "    positives = positives[positives != 0]\n",
    "    positive_score = (len(positives) / len (sentiment_scores))*100\n",
    "    #print('Positive sentiment ' + str(positive_score))\n",
    "    \n",
    "    negatives = np.array([x['neg'] for x in sentiment_scores])\n",
    "    negatives = negatives[negatives != 0]\n",
    "    negative_score = (len(negatives) / len (sentiment_scores))*100\n",
    "    #print('Negative sentiment ' + str(negative_score))\n",
    "    label = ['Postive','Negative','Neutral']\n",
    "    sentiment = pd.DataFrame({'Sentiment':[positive_score,\n",
    "                                           negative_score, 100-positive_score-negative_score]},\n",
    "                            index = label)\n",
    "    \n",
    "    sentiment.plot.pie(y='Sentiment', title='Sentiment of messages')\n",
    "    \n",
    "print_sentiments(messages_df['Sentiment'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
